{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– ReAct Agent Demo Notebook\n",
    "\n",
    "## Building Agentic AI with LangGraph & Google Gemini\n",
    "\n",
    "This notebook demonstrates how to build a **ReAct Agent** that can:\n",
    "- Think step-by-step\n",
    "- Use tools to interact with the world\n",
    "- Provide accurate, grounded responses\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langgraph langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "\n",
    "# Option 1: Set directly (not recommended for production)\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Use getpass for secure input\n",
    "from getpass import getpass\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the ReAct Pattern\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         ReAct Loop                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚   THOUGHT â†’ ACTION â†’ OBSERVATION    â”‚\n",
    "â”‚       â†‘          â†“                  â”‚\n",
    "â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚            â†“                        â”‚\n",
    "â”‚        RESPONSE                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Tools\n",
    "\n",
    "Tools are functions the agent can use to interact with the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Tool 1: Calculator\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression safely.\n",
    "    \n",
    "    Args:\n",
    "        expression: Math expression like '2 + 2', 'sqrt(16)', '10 * 5'\n",
    "    \"\"\"\n",
    "    safe_dict = {\n",
    "        \"sqrt\": math.sqrt, \"pow\": math.pow,\n",
    "        \"sin\": math.sin, \"cos\": math.cos,\n",
    "        \"pi\": math.pi, \"e\": math.e,\n",
    "        \"abs\": abs, \"round\": round,\n",
    "    }\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, safe_dict)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Tool 2: Get Current Time\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current time: {now.strftime('%A, %B %d, %Y at %I:%M %p')}\"\n",
    "\n",
    "# Tool 3: Simple Search (Simulated)\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information on a topic.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "    \"\"\"\n",
    "    # Simulated knowledge base\n",
    "    knowledge = {\n",
    "        \"langgraph\": \"LangGraph is a library for building stateful AI agents with LLMs.\",\n",
    "        \"react\": \"ReAct combines reasoning traces and actions in a synergistic loop.\",\n",
    "        \"gemini\": \"Gemini is Google's most capable AI model family.\",\n",
    "    }\n",
    "    \n",
    "    for key, value in knowledge.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return f\"No specific information found for: {query}\"\n",
    "\n",
    "# Collect all tools\n",
    "tools = [calculator, get_current_time, search]\n",
    "print(f\"âœ… Defined {len(tools)} tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize the LLM (Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"âœ… LLM initialized with tools bound!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the LangGraph Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, Sequence\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Define the state schema\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "# System prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant using the ReAct pattern.\n",
    "Think step-by-step, use tools when needed, and provide clear answers.\n",
    "Available tools: calculator, search, get_current_time.\"\"\"\n",
    "\n",
    "# Agent node function\n",
    "def agent_node(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    # Add system message if not present\n",
    "    if not messages or not isinstance(messages[0], SystemMessage):\n",
    "        messages = [SystemMessage(content=SYSTEM_PROMPT)] + list(messages)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Decision function\n",
    "def should_continue(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent = graph.compile()\n",
    "\n",
    "print(\"âœ… Agent graph built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph structure (text representation)\n",
    "print(\"\"\"\n",
    "Agent Graph Structure:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   START     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   Agent     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   Node      â”‚          â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚\n",
    "           â”‚                 â”‚\n",
    "           â–¼                 â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\n",
    "    â”‚  Decision   â”‚          â”‚\n",
    "    â”‚  (tools?)   â”‚          â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚\n",
    "           â”‚                 â”‚\n",
    "     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”           â”‚\n",
    "     â”‚           â”‚           â”‚\n",
    "     â–¼           â–¼           â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  Tools  â”‚ â”‚   END   â”‚      â”‚\n",
    "â”‚  Node   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚\n",
    "     â”‚                       â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query: str, verbose: bool = True):\n",
    "    \"\"\"Run the agent with a query.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"â“ Query: {query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    state = {\"messages\": [HumanMessage(content=query)]}\n",
    "    \n",
    "    if verbose:\n",
    "        # Stream to show steps\n",
    "        step_num = 1\n",
    "        for step in agent.stream(state):\n",
    "            for node_name, node_state in step.items():\n",
    "                print(f\"ğŸ“Œ Step {step_num} - Node: {node_name}\")\n",
    "                if \"messages\" in node_state:\n",
    "                    for msg in node_state[\"messages\"]:\n",
    "                        msg_type = type(msg).__name__\n",
    "                        content = msg.content[:100] + \"...\" if len(str(msg.content)) > 100 else msg.content\n",
    "                        print(f\"   â””â”€ {msg_type}: {content}\")\n",
    "                        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                            for tc in msg.tool_calls:\n",
    "                                print(f\"      ğŸ”§ Tool Call: {tc['name']}({tc['args']})\")\n",
    "            step_num += 1\n",
    "            print()\n",
    "    \n",
    "    # Get final result\n",
    "    result = agent.invoke(state)\n",
    "    final_response = result[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"{'â”€'*60}\")\n",
    "    print(f\"âœ… Final Answer: {final_response}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Math Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(\"What is 25 multiplied by 4, then add 50?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Information Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Time Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(\"What is the current date and time?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Complex Multi-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(\"If I buy 3 items at $15.50 each and have a 10% discount, what's my final total?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat (run this cell and type your questions)\n",
    "print(\"ğŸ® Interactive Mode - Type 'quit' to exit\")\n",
    "print(\"â”€\" * 40)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nğŸ’¬ You: \")\n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"\\nğŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "        if user_input.strip():\n",
    "            run_agent(user_input, verbose=False)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ‘‹ Session ended.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### What We Built:\n",
    "\n",
    "1. **Tools** - Calculator, Search, Time\n",
    "2. **LLM** - Google Gemini with tool binding\n",
    "3. **Agent Graph** - LangGraph state machine\n",
    "4. **ReAct Loop** - Think â†’ Act â†’ Observe\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- ğŸ¤– Agents can reason and use tools autonomously\n",
    "- ğŸ”„ LangGraph provides explicit control over the agent loop\n",
    "- ğŸ”§ Tools extend what agents can do\n",
    "- ğŸ“ System prompts guide agent behavior\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Add more tools (web search, databases)\n",
    "- Implement memory for multi-turn conversations\n",
    "- Add error handling and retries\n",
    "- Deploy as an API service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
